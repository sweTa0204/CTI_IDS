Glossary

Cross-Validation - A resampling technique used to evaluate machine learning models by training several models on subsets of the available input data and evaluating them on the complementary subset of the data. This helps in assessing how the results of a statistical analysis will generalize to an independent dataset.

Denial-of-Service (DoS) - A cyber-attack where the primary goal is to make a computer or network resource unavailable to its intended users. This is typically achieved by overwhelming the target with a flood of superfluous requests, causing it to crash or become unresponsive.

Explainable Artificial Intelligence (XAI) - A subfield of AI that focuses on creating systems and models that can explain their decisions and predictions to human users. It aims to address the "black box" problem, where even the developers cannot understand why an AI made a specific decision.

F1-Score - A statistical measure of a model's accuracy that considers both precision and recall. It is the harmonic mean of the two metrics and is particularly useful for evaluating models on imbalanced datasets.

Feature Engineering - The process of selecting, manipulating, and transforming raw data into features that can be used effectively in supervised learning algorithms. This process uses domain knowledge to create features that make machine learning algorithms work better.

Grid Search - A hyperparameter tuning technique used to find the optimal combination of hyperparameter values for a machine learning model. It exhaustively searches through a manually specified subset of the hyperparameter space.

Hyperparameter - A configuration variable that is external to the model and whose value cannot be estimated from data. The value of a hyperparameter is set before the learning process begins (e.g., learning rate in neural networks).

LIME (Local Interpretable Model-agnostic Explanations) - An XAI technique that explains the predictions of any machine learning model by approximating it with a simpler, interpretable model (like a linear model) in the local vicinity of a specific prediction.

Logistic Regression - A statistical algorithm used for binary classification, which predicts the probability of a target variable belonging to one of two classes. It models the relationship between a dependent binary variable and one or more independent variables.

Mitigation Engine - A component of a security system responsible for executing countermeasures in response to a detected threat. In this project, it translates XAI-driven insights into specific, automated defensive actions.

Multilayer Perceptron (MLP) - A class of feedforward artificial neural network (ANN). An MLP consists of at least three layers of nodes: an input layer, a hidden layer, and an output layer. Except for the input nodes, each node is a neuron that uses a nonlinear activation function.

Precision - A performance metric that measures the proportion of true positive instances among all instances predicted as positive. It answers the question: "Of all the alerts that were triggered, how many were actual attacks?"

Random Forest - An ensemble learning method that operates by constructing a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees.

SHAP (SHapley Additive exPlanations) - A game theory-based approach to explain the output of any machine learning model. It calculates the contribution of each feature to a prediction, providing a fair and accurate way to understand a model's behavior at both global and local levels.

Support Vector Machine (SVM) - A supervised machine learning algorithm used for both classification and regression tasks. It works by finding a hyperplane in an N-dimensional space (N being the number of features) that distinctly classifies the data points.

UNSW-NB15 - A comprehensive and widely used dataset for Network Intrusion Detection Systems (NIDS). It was created by the Australian Centre for Cyber Security and contains a mix of real-world normal network traffic and synthetically generated attack behaviors.

Variance Thresholding - A simple baseline approach to feature selection. It removes all features whose variance doesnâ€™t meet a certain threshold, effectively discarding features with the same value for most or all samples.

XGBoost (Extreme Gradient Boosting) - An optimized, distributed gradient boosting library designed for efficiency, flexibility, and portability. It is one of the most popular and effective machine learning algorithms for structured or tabular data.
