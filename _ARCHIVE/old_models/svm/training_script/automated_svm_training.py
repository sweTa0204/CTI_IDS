#!/usr/bin/env python3
"""
AUTOMATED SVM TRAINING - COMPLETE PIPELINE
=========================================

Support Vector Machine Training for DoS Detection
Layer 1: Training + Performance Evaluation
XAI Analysis: Layer 2
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_curve, auc,
    roc_auc_score
)
import joblib
import json
import time
from datetime import datetime
import warnings
import os

warnings.filterwarnings('ignore')

def main():
    print("ğŸ›¡ï¸ SVM AUTOMATED TRAINING")
    print("=" * 50)
    
    # Step 1: Load Data
    print("\nğŸ“Š STEP 1: LOADING DATA")
    print("=" * 40)
    
    data_path = "../../../../../../Final_year_project/dos_detection/working_dataset.csv"
    df = pd.read_csv(data_path)
    
    feature_names = [col for col in df.columns if col != 'label']
    X = df[feature_names]
    y = df['label']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"âœ… Data loaded successfully")
    print(f"ğŸ“Š Training samples: {len(X_train)}")
    print(f"ğŸ“Š Test samples: {len(X_test)}")
    print(f"ğŸ“Š Features: {feature_names}")
    
    # Step 2: Feature Scaling (Critical for SVM)
    print("\nğŸ“ STEP 2: FEATURE SCALING")
    print("=" * 40)
    
    print("ğŸ”§ Applying StandardScaler for SVM...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"âœ… Feature scaling completed")
    print(f"ğŸ“Š Training data scaled: {X_train_scaled.shape}")
    print(f"ğŸ“Š Test data scaled: {X_test_scaled.shape}")
    
    # Step 3: Hyperparameter Tuning
    print("\nğŸ”§ STEP 3: HYPERPARAMETER OPTIMIZATION")
    print("=" * 40)
    
    # Define parameter grid for SVM
    param_grid_info = {
        'C': [0.1, 1.0, 10.0, 100.0],  # Regularization parameter
        'kernel': ['linear', 'rbf', 'poly'],  # Kernel types
        'gamma': ['scale', 'auto', 0.001, 0.01],  # Kernel coefficient
        'degree': [2, 3]  # Degree for polynomial kernel
    }
    
    print(f"ğŸ” Parameter search strategy:")
    print(f"   Linear kernel: 4 C values")
    print(f"   RBF kernel: 4 C Ã— 4 gamma values = 16 combinations")
    print(f"   Poly kernel: 2 C Ã— 2 gamma Ã— 2 degree = 8 combinations")
    print(f"   Total approximate combinations: 28")
    
    # Perform Grid Search
    print(f"\nâš™ï¸ Starting Grid Search (3-fold CV for efficiency)...")
    
    svm_model = SVC(random_state=42, probability=True)  # probability=True for ROC analysis
    
    # Use simplified parameter grid for GridSearchCV
    param_grid = [
        # Linear kernel
        {
            'C': [0.1, 1.0, 10.0, 100.0],
            'kernel': ['linear']
        },
        # RBF kernel  
        {
            'C': [0.1, 1.0, 10.0, 100.0],
            'kernel': ['rbf'],
            'gamma': ['scale', 'auto', 0.001, 0.01]
        },
        # Polynomial kernel (limited to save time)
        {
            'C': [1.0, 10.0],
            'kernel': ['poly'],
            'gamma': ['scale', 'auto'],
            'degree': [2, 3]
        }
    ]
    
    grid_search = GridSearchCV(
        estimator=svm_model,
        param_grid=param_grid,
        cv=3,  # 3-fold for faster execution
        scoring='f1',
        n_jobs=-1,
        verbose=1
    )
    
    tuning_start = time.time()
    grid_search.fit(X_train_scaled, y_train)
    tuning_time = time.time() - tuning_start
    
    best_params = grid_search.best_params_
    best_score = grid_search.best_score_
    
    print(f"âœ… Hyperparameter tuning completed in {tuning_time:.2f} seconds")
    print(f"ğŸ† Best CV F1-Score: {best_score:.4f}")
    print(f"ğŸ¯ Best parameters:")
    for param, value in best_params.items():
        print(f"   {param}: {value}")
    
    # Step 4: Train Final Model
    print("\nğŸ›¡ï¸ STEP 4: TRAINING FINAL MODEL")
    print("=" * 40)
    
    # Train final model with best parameters
    final_params = {
        **best_params,
        'random_state': 42,
        'probability': True
    }
    
    start_time = time.time()
    final_model = SVC(**final_params)
    final_model.fit(X_train_scaled, y_train)
    training_time = time.time() - start_time
    
    print(f"âœ… Final model training completed in {training_time:.2f} seconds")
    print(f"ğŸ›¡ï¸ Kernel: {final_model.kernel}")
    print(f"ğŸ“Š C (Regularization): {final_model.C}")
    print(f"ğŸ“Š Number of support vectors: {final_model.n_support_}")
    print(f"ğŸ“Š Total support vectors: {len(final_model.support_)}")
    
    # Step 5: Evaluate Performance
    print("\nğŸ“ˆ STEP 5: PERFORMANCE EVALUATION")
    print("=" * 40)
    
    y_pred = final_model.predict(X_test_scaled)
    y_pred_proba = final_model.predict_proba(X_test_scaled)[:, 1]
    
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    
    print(f"ğŸ¯ PERFORMANCE METRICS:")
    print(f"   Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"   Precision: {precision:.4f} ({precision*100:.2f}%)")
    print(f"   Recall:    {recall:.4f} ({recall*100:.2f}%)")
    print(f"   F1-Score:  {f1:.4f} ({f1*100:.2f}%)")
    print(f"   ROC-AUC:   {roc_auc:.4f} ({roc_auc*100:.2f}%)")
    
    cm = confusion_matrix(y_test, y_pred)
    print(f"\nğŸ¯ CONFUSION MATRIX:")
    print(f"                 Predicted")
    print(f"               Normal  DoS")
    print(f"Actual Normal    {cm[0,0]:4d}  {cm[0,1]:4d}")
    print(f"       DoS       {cm[1,0]:4d}  {cm[1,1]:4d}")
    
    metrics = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'roc_auc': roc_auc,
        'cv_f1_score': best_score,
        'n_support_vectors': int(len(final_model.support_))
    }
    
    # Step 6: Feature Importance Analysis (Support Vector Analysis)
    print("\nğŸ” STEP 6: SUPPORT VECTOR ANALYSIS")
    print("=" * 40)
    
    # For linear kernel, we can get feature weights
    if final_model.kernel == 'linear':
        feature_weights = final_model.coef_[0]
        feature_importance = np.abs(feature_weights)
        
        feature_importance_df = pd.DataFrame({
            'feature': feature_names,
            'weight': feature_weights,
            'abs_weight': feature_importance,
            'importance': feature_importance / np.sum(feature_importance)
        }).sort_values('abs_weight', ascending=False)
        
        print(f"ğŸ† TOP 10 FEATURE WEIGHTS (Linear SVM):")
        for i, (_, row) in enumerate(feature_importance_df.head(10).iterrows(), 1):
            direction = "ğŸ“ˆ" if row['weight'] > 0 else "ğŸ“‰"
            print(f"   {i:2d}. {row['feature']:15s}: {row['importance']:.4f} ({row['importance']*100:.1f}%) {direction}")
        
        has_feature_importance = True
    else:
        print(f"ğŸ›¡ï¸ Non-linear kernel ({final_model.kernel}) - Feature importance not directly available")
        print(f"ğŸ“Š Support vector analysis:")
        print(f"   Normal class support vectors: {final_model.n_support_[0]}")
        print(f"   DoS class support vectors: {final_model.n_support_[1]}")
        print(f"   Support vector ratio: {final_model.n_support_[1]/final_model.n_support_[0]:.2f}")
        
        # Create a dummy feature importance for visualization
        feature_importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': [0.1] * len(feature_names)  # Equal importance placeholder
        })
        has_feature_importance = False
    
    # Step 7: Create Visualizations
    print("\nğŸ“Š STEP 7: CREATING VISUALIZATIONS")
    print("=" * 40)
    
    plt.style.use('default')
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('SVM - DoS Detection Performance', fontsize=16, fontweight='bold')
    
    # Confusion Matrix
    ax1 = axes[0, 0]
    sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', ax=ax1)
    ax1.set_title('Confusion Matrix')
    ax1.set_xlabel('Predicted')
    ax1.set_ylabel('Actual')
    ax1.set_xticklabels(['Normal', 'DoS'])
    ax1.set_yticklabels(['Normal', 'DoS'])
    
    # ROC Curve
    ax2 = axes[0, 1]
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    roc_auc_plot = auc(fpr, tpr)
    ax2.plot(fpr, tpr, color='darkorange', lw=2, 
            label=f'ROC curve (AUC = {roc_auc_plot:.3f})')
    ax2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    ax2.set_xlim([0.0, 1.0])
    ax2.set_ylim([0.0, 1.05])
    ax2.set_xlabel('False Positive Rate')
    ax2.set_ylabel('True Positive Rate')
    ax2.set_title('ROC Curve')
    ax2.legend(loc="lower right")
    
    # Feature Weights/Support Vector Analysis
    ax3 = axes[1, 0]
    if has_feature_importance:
        top_features = feature_importance_df.head(8)
        colors = ['darkorange' if weight > 0 else 'red' for weight in top_features['weight']]
        bars = ax3.barh(range(len(top_features)), top_features['weight'], color=colors)
        ax3.set_yticks(range(len(top_features)))
        ax3.set_yticklabels(top_features['feature'])
        ax3.set_xlabel('Feature Weight')
        ax3.set_title('Top 8 Feature Weights (Linear SVM)')
        ax3.invert_yaxis()
        ax3.axvline(x=0, color='black', linestyle='-', alpha=0.3)
        
        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax3.text(width + (0.01 if width > 0 else -0.01), bar.get_y() + bar.get_height()/2, 
                    f'{width:.3f}', ha='left' if width > 0 else 'right', va='center')
    else:
        # Support vector analysis for non-linear kernels
        classes = ['Normal', 'DoS']
        support_counts = final_model.n_support_
        bars = ax3.bar(classes, support_counts, color=['orange', 'red'])
        ax3.set_ylabel('Number of Support Vectors')
        ax3.set_title(f'Support Vector Distribution ({final_model.kernel} kernel)')
        
        for bar, count in zip(bars, support_counts):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + 5,
                    f'{count}', ha='center', va='bottom')
    
    # Performance Metrics
    ax4 = axes[1, 1]
    metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']
    values = [
        metrics['accuracy'],
        metrics['precision'],
        metrics['recall'],
        metrics['f1_score'],
        metrics['roc_auc']
    ]
    
    bars = ax4.bar(metric_names, values, color=['orange', 'darkorange', 'orangered', 'coral', 'peachpuff'])
    ax4.set_ylim([0, 1])
    ax4.set_ylabel('Score')
    ax4.set_title('Performance Metrics Summary')
    ax4.set_xticklabels(metric_names, rotation=45)
    
    for bar, value in zip(bars, values):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{value:.3f}', ha='center', va='bottom')
    
    plt.tight_layout()
    
    # Create results directory if needed
    os.makedirs('../results', exist_ok=True)
    plot_path = '../results/svm_performance.png'
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    print(f"âœ… Performance visualization saved: {plot_path}")
    plt.close()
    
    # Step 8: Save Model and Results
    print("\nğŸ’¾ STEP 8: SAVING MODEL AND RESULTS")
    print("=" * 40)
    
    try:
        # Create directories
        os.makedirs('../saved_model', exist_ok=True)
        os.makedirs('../results', exist_ok=True)
        os.makedirs('../documentation', exist_ok=True)
        
        # Save model and scaler
        model_path = '../saved_model/svm_model.pkl'
        scaler_path = '../saved_model/feature_scaler.pkl'
        
        joblib.dump(final_model, model_path)
        joblib.dump(scaler, scaler_path)
        print(f"âœ… Model saved: {model_path}")
        print(f"âœ… Scaler saved: {scaler_path}")
        
        # Save results
        results = {
            'model_name': 'SVM',
            'training_date': str(datetime.now()),
            'best_parameters': final_params,
            'performance_metrics': metrics,
            'training_time_seconds': training_time,
            'tuning_time_seconds': tuning_time,
            'feature_scaling': 'StandardScaler applied',
            'kernel_type': final_model.kernel
        }
        results_path = '../results/training_results.json'
        with open(results_path, 'w') as f:
            json.dump(results, f, indent=4)
        print(f"âœ… Training results saved: {results_path}")
        
        # Save feature names and weights (if applicable)
        feature_path = '../saved_model/feature_names.json'
        with open(feature_path, 'w') as f:
            json.dump(feature_names, f)
        print(f"âœ… Feature names saved: {feature_path}")
        
        if has_feature_importance:
            weights_path = '../results/feature_weights.json'
            weights_data = {
                'features': feature_names,
                'weights': feature_weights.tolist() if 'feature_weights' in locals() else [],
                'feature_importance': feature_importance_df.to_dict('records')
            }
            with open(weights_path, 'w') as f:
                json.dump(weights_data, f, indent=4)
            print(f"âœ… Feature weights saved: {weights_path}")
        
    except Exception as e:
        print(f"âŒ Error saving files: {str(e)}")
        return False
    
    # Step 9: Generate Report
    print("\nğŸ“‹ STEP 9: GENERATING TRAINING REPORT")
    print("=" * 40)
    
    report = f"""# SVM TRAINING REPORT
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## MODEL CONFIGURATION
- Algorithm: Support Vector Machine (SVM)
- Features: 10 network traffic features
- Feature Scaling: StandardScaler applied
- Training Time: {training_time:.2f} seconds
- Hyperparameter Tuning Time: {tuning_time:.2f} seconds
- Cross-Validation: 3-fold
- Class Balance: Balanced (50-50)

## BEST HYPERPARAMETERS
- Kernel: {final_params['kernel']}
- C (Regularization): {final_params['C']}
{"- Gamma: " + str(final_params['gamma']) if 'gamma' in final_params else ""}
{"- Degree: " + str(final_params['degree']) if 'degree' in final_params else ""}

## PERFORMANCE METRICS
- Accuracy: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)
- Precision: {metrics['precision']:.4f} ({metrics['precision']*100:.2f}%)
- Recall: {metrics['recall']:.4f} ({metrics['recall']*100:.2f}%)
- F1-Score: {metrics['f1_score']:.4f} ({metrics['f1_score']*100:.2f}%)
- ROC-AUC: {metrics['roc_auc']:.4f} ({metrics['roc_auc']*100:.2f}%)
- CV F1-Score: {metrics['cv_f1_score']:.4f} ({metrics['cv_f1_score']*100:.2f}%)

## SUPPORT VECTOR ANALYSIS
- Total Support Vectors: {metrics['n_support_vectors']}
- Normal Class Support Vectors: {final_model.n_support_[0]}
- DoS Class Support Vectors: {final_model.n_support_[1]}
- Support Vector Efficiency: {(metrics['n_support_vectors']/len(X_train)*100):.2f}% of training data

"""
    
    if has_feature_importance:
        report += "## TOP 5 IMPORTANT FEATURES (by weight magnitude)\n"
        for i, (_, row) in enumerate(feature_importance_df.head(5).iterrows(), 1):
            direction = "â†—ï¸" if row['weight'] > 0 else "â†˜ï¸"
            report += f"{i}. {row['feature']}: {row['importance']:.4f} ({row['importance']*100:.1f}%) {direction}\n"
    else:
        report += f"## KERNEL ANALYSIS\n"
        report += f"- Non-linear kernel ({final_model.kernel}) used\n"
        report += f"- Feature weights not directly interpretable\n"
        report += f"- Model captures complex decision boundaries\n"
    
    report += f"""
## CONFUSION MATRIX ANALYSIS
- True Negatives (Normal correctly classified): {cm[0,0]}
- False Positives (Normal misclassified as DoS): {cm[0,1]}
- False Negatives (DoS misclassified as Normal): {cm[1,0]}
- True Positives (DoS correctly classified): {cm[1,1]}

## SVM INSIGHTS
- Kernel method enables non-linear decision boundaries
- Support vectors define the decision boundary
- Model complexity controlled by C parameter
- {"Linear interpretability available" if has_feature_importance else "Non-linear kernel captures complex patterns"}

## 4-MODEL COMPARISON COMPLETE
âœ… Random Forest: 95.29% accuracy
âœ… XGBoost: 95.54% accuracy  
âœ… Logistic Regression: 78.18% accuracy
âœ… SVM: {metrics['accuracy']*100:.2f}% accuracy

## ANALYSIS SUMMARY
âœ… Feature Scaling: COMPLETED (StandardScaler)
âœ… Hyperparameter Tuning: COMPLETED
âœ… Training: COMPLETED
âœ… Evaluation: COMPLETED  
âœ… Model Saved: COMPLETED
âœ… Visualizations: COMPLETED
âœ… 4-Model Comparison: COMPLETED
â³ XAI Analysis: READY (Layer 2)

## NEXT STEPS
1. Generate comprehensive 4-model comparison report
2. Identify best performing model for production
3. Proceed to Layer 2: XAI/SHAP analysis
4. Create final research documentation

---
SVM Training Successfully Completed - All 4 Models Ready for Analysis
"""
    
    report_path = '../documentation/training_report.md'
    with open(report_path, 'w') as f:
        f.write(report)
    
    print(f"âœ… Training report saved: {report_path}")
    
    # Final Summary
    print(f"\nğŸ‰ SVM TRAINING COMPLETED!")
    print("=" * 50)
    print(f"ğŸ¯ Final Accuracy: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)")
    print(f"ğŸ¯ Final F1-Score: {metrics['f1_score']:.4f} ({metrics['f1_score']*100:.2f}%)")
    print(f"ğŸ¯ Final ROC-AUC: {metrics['roc_auc']:.4f} ({metrics['roc_auc']*100:.2f}%)")
    print(f"ğŸ›¡ï¸ Kernel: {final_model.kernel}")
    print(f"ğŸ“Š Support Vectors: {metrics['n_support_vectors']}")
    print(f"â±ï¸  Training Time: {training_time:.2f} seconds")
    print(f"ğŸ”§ Tuning Time: {tuning_time:.2f} seconds")
    print(f"ğŸ’¾ Model saved and ready for deployment")
    print(f"ğŸ“Š All results and visualizations generated")
    
    print(f"\nğŸ† 4-MODEL COMPARISON COMPLETE:")
    print(f"   1. âœ… Random Forest: 95.29% accuracy")
    print(f"   2. âœ… XGBoost: 95.54% accuracy (LEADER)")
    print(f"   3. âœ… Logistic Regression: 78.18% accuracy")
    print(f"   4. âœ… SVM: {metrics['accuracy']*100:.2f}% accuracy")
    print(f"   5. ğŸš€ Layer 2: XAI analysis READY")
    
    print(f"\nğŸ¯ RESEARCH COMPLETION STATUS:")
    print(f"   ğŸ“Š Model Training: COMPLETED (4/4)")
    print(f"   ğŸ“ˆ Performance Analysis: COMPLETED")
    print(f"   ğŸ” Feature Importance: COMPLETED")
    print(f"   ğŸ¨ Visualizations: COMPLETED")
    print(f"   ğŸ“‹ Documentation: COMPLETED")
    print(f"   ğŸš€ Ready for Layer 2: XAI Analysis")
    
    return True

if __name__ == "__main__":
    success = main()
    if success:
        print(f"\nâœ… SVM training pipeline completed successfully!")
        print(f"ğŸ‰ ALL 4 MODELS TRAINING COMPLETED - READY FOR COMPREHENSIVE ANALYSIS!")
    else:
        print(f"\nâŒ Training encountered issues. Check logs above.")
